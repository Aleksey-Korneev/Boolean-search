{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание по булеву поиску\n",
    "\n",
    "Задание выполнил Корнеев Алексей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на содержание файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['z\\x10\\x00\\x00', '*http://lenta.ru/news/2009/06/17/procedure/\\x1a', '07:26,', '17', 'июня', '2009', 'генпрокуратура', 'подготовила', 'документы', 'для', 'экстрадиции', 'чичваркина', 'генпрокуратура', 'рф', 'начала', 'процедуру', 'экстрадиции', 'из', 'великобритании', 'бывшего', 'совладельца', 'компании', '\"евросеть\"', 'евгения', 'чичваркина,', 'пишет', 'в', 'среду', 'газета', '\"', 'коммерсант', '\".', 'по', 'данным', 'издания,', 'недавно', 'российское', 'ведомство', 'посетили', 'представители', 'правоохранительных', 'органов', 'великобритании,', 'с', 'которыми', 'был', 'согласован', 'перечень', 'необходимых', 'документов.', 'бумаги', 'уже', 'переведены', 'на', 'английский', 'язык', 'и', 'вскоре', 'будут', 'направлены', 'в', 'лондон.', 'чичваркин,', 'который', 'обвиняется', 'в', 'причастности', 'к', 'похищению', 'человека', 'и', 'вымогательству,', 'был', 'заочно', 'арестован', 'басманным', 'судом', 'в', 'январе', '2009', 'года,', 'напоминает', 'издание.', 'вместе', 'ним', 'по', 'делу', 'о', 'похищении', 'андрея', 'власкина,', 'работавшего', 'экспедитором', 'в', '\"евросети\",', 'проходят', 'бывший', 'вице-президент', 'компании', 'борис']\n",
      "['\\x12\\x00\\x00', ',http://lenta.ru/vojna/2000/01/26/saidullaev/\\x1a$23:43,', '26', 'января', '2000', 'сайдуллаев', 'едет', 'на', 'переговоры', 'с', 'масхадовым', 'продолжить', 'переговоры', 'с', 'чеченскими', 'полевыми', 'командирами', 'собирается', 'глава', 'госсовета', 'республики', 'малик', 'сайдуллаев.', 'он', 'собирается', 'договориться', 'с', 'ними', 'о', 'добровольной', 'сдаче', 'оружия.', 'по', 'информации', '\"интерфакса\"', 'сайдуллаев', 'отправился', 'в', 'чечню', 'с', 'согласия', 'министерства', 'обороны', 'и', 'других', 'федеральных', 'силовых', 'ведомств.', 'сайдуллаев', 'рассчитывает', 'лично', 'встретиться', 'с', 'президентом', 'ченчи', 'асланом', 'масхадовым', 'и', 'обсудить,', '\"как', 'лучше', 'ему', 'поступить', 'для', 'того,', 'чтобы', 'война', 'в', 'чечне', 'была', 'прекращена\".', '\"у', 'меня', 'есть', 'конкретный', 'план', 'на', 'этот', 'счет\",', '-', 'утверждает', 'сайдуллаев.', 'подробности', 'же', 'он', 'рассказывать', 'отказался.', 'по', 'мнению', 'сайдуллаева', 'для', 'прекращения', 'вооруженного', 'сопротивления', '\"полевым', 'командирам', 'нужны', 'гарантии,', 'в', 'том']\n",
      "['\\x13\\x00\\x00', \"3http://lenta.ru/news/2015/12/22/corruption_reiting/\\x1a'15:28,\", '22', 'декабря', '2015', 'pwc', 'назвала', 'самые', 'подверженные', 'коррупции', 'отрасли', 'в', 'россии', 'консалтинговая', 'компания', 'pricewaterhousecoopers', '(pwc)', 'подготовила', 'свой', 'первый', 'рейтинг', 'индекса', 'противодействия', 'коррупции', '(abci),', 'измеряющего', 'уровень', 'соответствия', 'российских', 'игроков', 'рынка', 'требованиям', 'антикоррупционного', 'законодательства.', 'об', 'этом', 'говорится', 'в', 'пресс-релизе', 'pwc,', 'поступившем', 'в', 'редакцию', '«ленты.ру».', 'в', 'сообщении', 'отмечается,', 'что', 'крупнейшие', 'российские', 'компании', 'достигли', 'показателя', 'abci', 'на', 'уровне', '63', 'процентов', '(чем', 'выше', 'индекс,', 'тем', 'лучше', 'соблюдаются', 'антикоррупционные', 'законы),', 'несмотря', 'на', 'сравнительную', 'молодость', 'законодательства,', 'направленного', 'на', 'борьбу', 'с', 'коррупцией.', 'если', 'в', 'россии', 'такие', 'законы', 'заработали', 'только', '6-7', 'лет', 'назад,', 'то,', 'к', 'примеру,', 'в', 'сша', 'закон', 'о', 'противодействии', 'коррупции', 'за', 'рубежом', 'вступил', 'в', 'силу']\n",
      "['\\x00\\x00', \"'http://lenta.ru/news/2008/10/21/trunov/\\x1a\\x1321:04,\", '21', 'октября', '2008', 'пострадавшие', 'от', 'теракта', 'на', 'дубровке', 'пожаловались', 'на', 'мародерство', 'пострадавшие', 'в', 'результате', 'теракта', 'в', 'театральном', 'центре', 'на', 'дубровке', 'потребовали', 'от', 'правительства', 'и', 'прокуратуры', 'возмещения', 'вреда,', 'нанесенного', 'мародерами.', 'об', 'этом', 'во', 'вторник', 'сообщает', 'риа', 'новости', '.', 'в', 'настоящее', 'время', 'в', 'замоскворецкий', 'суд', 'москвы', 'подано', 'два', 'иска', 'жертв', 'мародеров.', 'потерпевшая', 'екатерина', 'долгая', 'требует', 'выплаты', '662', 'тысячи', '300', 'рублей,', 'а', 'семья', 'погибшего', 'журналиста', 'максима', 'михайлова', '-', 'примерно', '526', 'тысяч', 'рублей.', 'по', 'словам', 'адвоката', 'истцов', 'игоря', 'трунова,', 'впоследствии', 'число', 'подобных', 'жалоб', 'должно', 'возрасти', 'до', 'десяти.', 'трунов', 'заявил,', 'что', 'пострадавшие', 'во', 'время', 'теракта', 'требовали', 'завести', 'уголовное', 'дело', 'о', 'мародерстве.', '\"однако', 'нам']\n",
      "['\\x08\\x00\\x00', \"'http://lenta.ru/news/2008/09/10/salary/\\x1a\\x0f15:04,\", '10', 'сентября', '2008', 'зарплата', 'региональных', 'чиновников', 'на', '70', 'процентов', 'превысила', 'среднюю', 'по', 'стране', 'за', 'первые', 'шесть', 'месяцев', '2008', 'года', 'средняя', 'зарплата', 'чиновников', 'в', 'российских', 'регионах', 'выросла', 'на', '32', 'процента', 'и', 'составила', 'около', '1300', 'долларов', 'в', 'месяц', '(30396', 'рублей).', 'об', 'этом', 'сообщается', 'на', 'сайте', 'федеральной', 'службы', 'государственной', 'статистики', '(росстата).', 'в', 'то', 'же', 'время', 'средняя', 'зарплата', 'по', 'стране', 'за', 'тот', 'же', 'период', 'составила', 'около', '750', 'долларов', '(17450', 'рублей).', 'таким', 'образом,', 'выплаты', 'чиновникам', 'более', 'чем', 'на', '70', 'процентов', 'превысили', 'средние', 'по', 'россии.', 'самые', 'большие', 'зарплаты', 'у', 'чиновников', 'ненецкого', 'ао', '-', '92208', 'рублей,', 'самые', 'маленькие', '-', 'в', 'кабардино-балкарии,', '13924', 'рубля.', 'для', 'сравнения,']\n",
      "['q\\x08\\x00\\x00', '%http://lenta.ru/news/2005/10/03/fire/\\x1a\\x1020:35,', '3', 'октября', '2005', 'в', 'екатеринбурге', 'произошел', 'пожар', 'в', 'студенческом', 'общежитии', 'в', 'екатеринбурге', 'произошел', 'пожар', 'в', 'общежитии', 'уральского', 'государственного', 'университета.', 'из', 'здания', 'было', 'эвакуировано', 'более', '200', 'человек,', 'сообщает', 'информационное', 'агентство', '\"новый', 'регион\"', '.', 'возгорание', 'возникло', 'в', 'жилой', 'комнате', 'на', 'первом', 'этаже', '3-го', 'корпуса', 'общежития,', 'расположенного', 'по', 'адресу', 'улица', 'большакова,', '79.', 'дым', 'быстро', 'распространился', 'по', 'пятиэтажному', 'зданию.', 'проживающие', 'на', 'нижних', 'этажах', 'студенты', 'выбирались', 'из', 'окон', 'на', 'козырек', 'подъезда,', 'откуда', 'спрыгивали', 'на', 'землю.', 'никто', 'из', 'них', 'серьезно', 'не', 'пострадал.', 'остальных,', 'в', 'том', 'числе', '4-летнюю', 'девочку,', 'находившуюся', 'в', 'комнате,', 'где', 'возник', 'пожар,', 'эвакуировали', 'прибывшие', 'пожарные.', 'на', 'месте', 'пожара', 'работали', '8', 'пожарных', 'машин,']\n",
      "['\\x00\\x00', \"'http://lenta.ru/world/2004/06/09/cross/\\x1a\\x1320:26,\", '9', 'июня', '2004', 'американцы', 'разрешили', 'красному', 'кресту', 'осмотреть', 'тюрьму', 'в', 'афганистане', 'американское', 'военное', 'командование', 'объявило', 'о', 'том,', 'что', 'откроет', 'для', 'представителей', 'красного', 'креста', 'еще', 'одну', 'тюрьму', 'в', 'афганистане,', 'передает', 'associated', 'press.', 'до', 'сих', 'пор', 'из', 'приблизительно', '20', 'мест', 'лишения', 'свободы,', 'которые', 'используют', 'миротворцы', 'в', 'этой', 'стране,', 'международная', 'организация', 'могла', 'осматривать', 'только', 'одно.', 'а', 'местная', 'комиссия', 'по', 'правам', 'человека', 'не', 'была', 'допущены', 'ни', 'в', 'одно', 'из', 'них.', 'по', 'данным', 'агентства,', 'военные', 'держат', 'в', 'афганских', 'тюрьмах', 'около', '400', 'пленников.', 'узнать', 'о', 'том,', 'как', 'с', 'ними', 'обращаются', 'красный', 'крест', 'подталкивает', 'скандал', 'с', 'пытками', 'заключенных', 'в', 'иракской', 'тюрьме', 'абу-граиб.', 'к', 'тому', 'же']\n",
      "['\\x08\\x00\\x00', '(http://lenta.ru/sport/2001/04/02/hockey/\\x1a\\x1104:35,', '2', 'апреля', '2001', 'сборная', 'россии', '—', 'чемпион', 'мира', 'по', 'хоккею', 'с', 'мячом', 'уверенной', 'победой', 'российской', 'сборной', 'завершился', 'чемпионат', 'мира', 'по', 'хоккею', 'с', 'мячом,', 'проходивший', 'в', 'финляндии.', 'в', 'финальном', 'матче', 'россияне', 'разгромили', 'главного', 'конкурента', 'в', 'борьбе', 'за', '\"золото\",', 'шведов', 'со', 'счетом', '6:1.', 'российской', 'команде', 'удалось', 'сохранить', 'чемпионский', 'титул,', 'добытый', 'два', 'года', 'назад', 'на', 'мировом', 'первенстве', 'в', 'архангельске.', 'несмотря', 'на', 'крупный', 'счет,', 'исход', 'решающего', 'матча', 'определился', 'лишь', 'в', 'его', 'концовке.', 'первый', 'тайм', 'закончился', 'с', 'минимальным', 'преимуществом', 'россиян', '-', '1:0.', 'единственный', 'мяч', 'за', 'три', 'минуты', 'до', 'перерыва', 'забросил', 'грачев.', 'еще', 'за', '15', 'минут', 'до', 'конца', 'матча', 'сборная', 'россии', 'выигрывала', 'с', 'преимуществом']\n",
      "CPU times: user 632 ms, sys: 99.5 ms, total: 732 ms\n",
      "Wall time: 746 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(8):\n",
    "    # filename = 'C:/Users/apkor/Desktop/Учеба/4 семестр/Инфопоиск/Boolean_search/lenta_ru_dump' + \\\n",
    "    filename = 'dumps' + \\\n",
    "        '/dump_' + str(i + 1) + '.gz'\n",
    "    data = []\n",
    "    with gzip.open(filename) as file:\n",
    "        data.extend(file.read().decode('utf-8', errors = 'ignore').lower().split())\n",
    "    print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных\n",
    "\n",
    "Токенизируем текст и удалим лишние символы, сохраним список url и множество всех слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(path):\n",
    "    \"\"\"\n",
    "    Предобработка сырых данных.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    num_of_files = 8\n",
    "    for i in range(num_of_files):\n",
    "        filename = path + '/dump_' + str(i + 1) + '.gz'\n",
    "        with gzip.open(filename) as file:\n",
    "            data.extend(file.read().decode('utf-8', errors = 'ignore').lower().split())\n",
    "    \n",
    "    words = set(data) # список всех слов в корпусе текстов\n",
    "    urls = dict() # список всех сайтов\n",
    "    buf = []\n",
    "    \n",
    "    def __parse_url(url):\n",
    "        \"\"\"\n",
    "        Удаление лишних символов.\n",
    "        \"\"\"\n",
    "        clear_url = ''\n",
    "        ord_point = 46 # = ord('.')\n",
    "        for c in url:\n",
    "            clear_url += c\n",
    "            if len(clear_url) == 4 and clear_url != 'http':\n",
    "                clear_url = clear_url[1:]\n",
    "            if ord(clear_url[-1]) < ord_point and 'http' in clear_url: # url кончился, появился лишний символ\n",
    "                # break\n",
    "                return clear_url[:-1]\n",
    "        return clear_url[:-1]\n",
    "   \n",
    "\n",
    "    for word in data:\n",
    "        if 'http://lenta' in word: # ссылки на lenta.ru могут находиться на самих страницах lenta.ru\n",
    "            if len(buf) > 2:\n",
    "                urls[__parse_url(buf[0])] = buf[1:]\n",
    "                words.remove(buf[0])\n",
    "            # buf.clear()\n",
    "            buf = []\n",
    "        buf.append(word)\n",
    "    \n",
    "    return words, urls    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 s, sys: 92.4 ms, total: 2.71 s\n",
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# words, urls = data_preprocessing('C:/Users/apkor/Desktop/Учеба/4 семестр/Инфопоиск/Boolean_search/dumps')\n",
    "words, urls = data_preprocessing('dumps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 135 ms, sys: 3.94 ms, total: 139 ms\n",
      "Wall time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_to_id = { word : id_ for (id_, word) in enumerate(words) }    # словарь { слово : id слова}\n",
    "id_to_url = { id_ : url for (id_, url) in enumerate(urls.keys()) } # словарь { id документа : url сайта }\n",
    "url_to_id = { url : id_ for (id_, url) in enumerate(urls.keys()) } # словарь { url сайта : id документа }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284157, 9876, 9876)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD_TO_ID_LEN = len(word_to_id)\n",
    "len(word_to_id), len(id_to_url), len(url_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сжатие (Simple 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple9:\n",
    "    def __init__(self):\n",
    "        self.shifts = [1, 2, 3, 4, 5, 7, 9, 14, 28]\n",
    "        self.masks = [i * (1 << 28) for i in range(1, 10)]\n",
    "        self.encode_type = \\\n",
    "            [ [ self.shifts[-i - 1], 2**self.shifts[i] - 1, self.masks[-i - 1], self.shifts[i] ] \\\n",
    "            for i in range(len(self.masks)) ]\n",
    "        self.decode_type = \\\n",
    "            { self.masks[-i - 1] : [ self.shifts[-i - 1], 2**self.shifts[i] - 1, self.shifts[i] ] \\\n",
    "            for i in range(len(self.masks)) }\n",
    "        \n",
    "    def simple9_encode(self, content):\n",
    "        \"\"\"\n",
    "        Кодирование списка элементов content.\n",
    "        \"\"\"\n",
    "        offset = 0\n",
    "        res = []\n",
    "        while offset < len(content):\n",
    "            for encode_type in self.encode_type:\n",
    "                (n, upper, code, single_shift) = encode_type\n",
    "                if offset + n <= len(content) and max(content[offset:offset + n]) <= upper:\n",
    "                    cur_val = content[offset]\n",
    "                    for i in range(1, n):\n",
    "                        cur_val |= (content[offset + i] << (i * single_shift))\n",
    "                    offset += n\n",
    "                    res.append(code | cur_val)\n",
    "                    break\n",
    "        return res\n",
    "    \n",
    "    def simple9_decode(self, content):\n",
    "        \"\"\"\n",
    "        Декодирование списка элементов content.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for item in content:\n",
    "            (n, upper, single_shift) = self.decode_type[0xf0000000 & item]\n",
    "            data = 0x0fffffff & item\n",
    "            \n",
    "            for i in range(n):\n",
    "                res.append(upper & data)\n",
    "                data >>= single_shift\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.78 s, sys: 32 ms, total: 2.82 s\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reversed_index = defaultdict(list)\n",
    "for id_, (url, words_list) in enumerate(urls.items()):\n",
    "    for word in words_list:\n",
    "        reversed_index[word_to_id[word]].append(url_to_id[url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 s, sys: 27.8 ms, total: 3.28 s\n",
      "Wall time: 3.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from copy import deepcopy # для передачи списков в ф-ции\n",
    "\n",
    "data = []\n",
    "for key, value in reversed_index.items():\n",
    "    list_copy = deepcopy(value)\n",
    "    for i in range(len(list_copy) - 1, 0, -1):\n",
    "        list_copy[i] -= list_copy[i - 1]\n",
    "    tmp_list = [key, len(list_copy)] + list_copy # [ id, n, 1st item, 2nd item, ..., nth item ]\n",
    "    data.extend(tmp_list) # id, n, 1st item, 2nd item, ..., nth item, id, n, 1st item, 2nd item, ..., nth item, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.77 s, sys: 68.4 ms, total: 8.84 s\n",
      "Wall time: 8.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "simple9_encoder_decoder = Simple9()\n",
    "data_compressed = simple9_encoder_decoder.simple9_encode(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом этапе происходит процесс передачи данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 56 ms, total: 1.45 s\n",
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_decompressed = simple9_encoder_decoder.simple9_decode(data_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(data) == len(data_decompressed))\n",
    "for i in range(len(data)):\n",
    "    assert(data[i] == data_decompressed[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверим, что восстановленный по сжатым данным обратный индекс идентичен исходному."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.97 s, sys: 56 ms, total: 5.03 s\n",
      "Wall time: 5.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reversed_index_decoded = defaultdict(list)\n",
    "flag = 0 # тип декодируемого элемента:\n",
    "         # 0 - id слова\n",
    "         # 1 - n\n",
    "         # 2 - список id документов\n",
    "for item in data_decompressed:\n",
    "    if flag == 0:\n",
    "        key = item\n",
    "        flag += 1\n",
    "    elif flag == 1:\n",
    "        n = item\n",
    "        cur_list = []\n",
    "        flag += 1\n",
    "    else:\n",
    "        n -= 1\n",
    "        if len(cur_list) > 0:\n",
    "            cur_list.append(item + cur_list[-1])\n",
    "        else:\n",
    "            cur_list.append(item)\n",
    "        \n",
    "        if n == 0:\n",
    "            reversed_index_decoded[key] = deepcopy(cur_list)\n",
    "            flag = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(reversed_index) == len(reversed_index_decoded))\n",
    "for i in range(len(reversed_index)):    \n",
    "    assert(reversed_index[i] == reversed_index_decoded[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм сжатия работает корректно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del reversed_index_decoded # удаляем ненужную копию обратного индекса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Булев поиск\n",
    "\n",
    "На последнем этапе необходимо выполнить несколько задач:\n",
    "1. Реализовать потоковую обработку дерева запросов.\n",
    "2. Перевести запрос в обратную польскую нотацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_idx = set() # множество индексов вершин дерева поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def search(query, id_to_url):\n",
    "    \"\"\"\n",
    "    Поиск документов, удовлетворяющих булевому запросу.\n",
    "    \"\"\"\n",
    "    global nodes_idx\n",
    "    search_tree = dict()\n",
    "    \n",
    "    def __streaming_tree_processing(search_tree, root, reversed_index, word_to_id):\n",
    "        \"\"\"\n",
    "        Потоковая обработка дерева.\n",
    "        \"\"\"\n",
    "        \n",
    "        def __binary_search(list_, key, left = 0, right = -100): # можно еще подумать над выбором константы,\n",
    "                                                                 # 100 кажется оптимальным значением\n",
    "            \"\"\"\n",
    "            Бинарный поиск.\n",
    "            \"\"\"\n",
    "            if right == -100:\n",
    "                right = len(list_) - 1\n",
    "            if left == len(list_):\n",
    "                return left\n",
    "            if left > right:\n",
    "                return left\n",
    "            mid = ((left + right) // 2)\n",
    "            if list_[mid] < key:\n",
    "                return __binary_search(list_, key, mid + 1, right)\n",
    "            elif list_[mid] > key:\n",
    "                return __binary_search(list_, key, left, mid - 1)\n",
    "            return mid\n",
    "\n",
    "        idx_res = -1\n",
    "        res = []\n",
    "        \n",
    "        def __run_search(ptr, idx_res):\n",
    "            \"\"\"\n",
    "            Рекурсивный обход дерева.\n",
    "            \"\"\"\n",
    "            node = search_tree[ptr]\n",
    "            if node[0] == 'binary':\n",
    "                if node[1] == '&':\n",
    "                    return max(\n",
    "                        __run_search(node[2], idx_res),\n",
    "                        __run_search(node[3], idx_res)\n",
    "                    )\n",
    "                if node[1] == '|':\n",
    "                    return min(\n",
    "                        __run_search(node[2], idx_res),\n",
    "                        __run_search(node[3], idx_res)\n",
    "                    )\n",
    "            \n",
    "            elif node[0] == 'unary':\n",
    "                if node[1] == '!':\n",
    "                    tmp = __run_search(node[2], idx_res)\n",
    "                    return (tmp + 1) if tmp == idx_res else idx_res\n",
    "            \n",
    "            elif node[0] == 'operand':\n",
    "                docs = reversed_index[node[1]]\n",
    "                node[2] = __binary_search(docs, idx_res, left = node[2])\n",
    "                if node[2] == len(docs):\n",
    "                    return float('inf')\n",
    "                elif docs[node[2]] >= idx_res:\n",
    "                    return docs[node[2]]\n",
    "            \n",
    "        while idx_res < max_idx_res:\n",
    "            query_out = __run_search(root, idx_res)\n",
    "            if idx_res == query_out:\n",
    "                res.append(idx_res)\n",
    "                idx_res += 1\n",
    "            else:\n",
    "                if idx_res < query_out:\n",
    "                    idx_res = query_out\n",
    "        return res\n",
    "    \n",
    "    def __create_node(stack, item, item_type):\n",
    "        new_idx = __get_unique_idx()\n",
    "        if item_type == 'binary':\n",
    "            node = { new_idx : [ item_type, item, stack[-2], stack[-1] ] }\n",
    "            del stack[-2:]\n",
    "        elif item_type == 'unary':\n",
    "            node = { new_idx : [ item_type, item, stack[-1] ] }\n",
    "            stack.pop()\n",
    "        elif item_type == 'operand':\n",
    "            node = { new_idx : [ item_type, item, 0 ] }\n",
    "            \n",
    "        stack.append(new_idx)\n",
    "        search_tree.update(node)\n",
    "        \n",
    "        return stack\n",
    "    \n",
    "    \n",
    "    def __transform_query(query):\n",
    "        \"\"\"\n",
    "        Преобразование запроса в список строк трех типов: \\\n",
    "        скобки, операнды и операции над множествами (унарные и бинарные).\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        token = \"\"\n",
    "        \n",
    "        for c in query.lower():\n",
    "            if c.isalpha(): # часть операнда\n",
    "                token += c\n",
    "            else:\n",
    "                if token.strip(): # операнд считан целиком, лишние символы удалены\n",
    "                    res.append(token)\n",
    "                token = \"\"\n",
    "                if c.strip(): # операция над множествами\n",
    "                    res.append(c)\n",
    "        if token.strip(): # последний/-ая операнд / операция над множеством\n",
    "            res.append(token)\n",
    "        return res\n",
    "    \n",
    "    def __reverse_polish_notation(query_list):\n",
    "        \"\"\"\n",
    "        Перевод запроса в обратную польскую нотацию.\n",
    "        \"\"\"\n",
    "        rpn = []\n",
    "        stack = []\n",
    "        priorities = {\n",
    "            '(' : 1,\n",
    "            '|' : 2,\n",
    "            '&' : 3,\n",
    "            '!' : 4\n",
    "        } # приоритеты операций над множествами\n",
    "        \n",
    "        for item in query_list:\n",
    "            if item == '(':\n",
    "                stack.append('(')\n",
    "            elif item in priorities.keys():\n",
    "                while len(stack) > 0 and priorities[stack[-1]] >= priorities[item]:\n",
    "                    rpn.append(stack[-1])\n",
    "                    stack.pop()\n",
    "                stack.append(item)\n",
    "            elif item == ')':\n",
    "                while stack[-1] != '(':\n",
    "                    rpn.append(stack[-1])\n",
    "                    stack.pop()\n",
    "                stack.pop()\n",
    "            else:\n",
    "                rpn.append(item)\n",
    "        \n",
    "        rpn.extend(reversed(stack))\n",
    "        \n",
    "        return rpn\n",
    "    \n",
    "    def __get_unique_idx():\n",
    "        # global nodes_idx\n",
    "        \n",
    "        new_idx = randint(0, WORD_TO_ID_LEN)\n",
    "        while new_idx in nodes_idx:\n",
    "            new_idx = randint(0, WORD_TO_ID_LEN)\n",
    "        nodes_idx.add(new_idx)\n",
    "        return new_idx\n",
    "    \n",
    "    # получаем query_list\n",
    "    query_list = __transform_query(query)\n",
    "    \n",
    "    rpn = __reverse_polish_notation(query_list)\n",
    "    \n",
    "    stack = []\n",
    "    \n",
    "    for item in rpn:\n",
    "        if item == '!':\n",
    "            stack = __create_node(stack, item, 'unary')\n",
    "        elif item == '&' or item == '|':\n",
    "            stack = __create_node(stack, item, 'binary')\n",
    "        else:\n",
    "            stack = __create_node(stack, word_to_id[item], 'operand')\n",
    "    \n",
    "    root = stack[0]\n",
    "    \n",
    "    max_idx_res = max(url_to_id.values())\n",
    "    doc_idx = __streaming_tree_processing(search_tree, root, reversed_index, word_to_id)\n",
    "    output = []\n",
    "    for id_ in doc_idx:\n",
    "        output.append(id_to_url[id_])\n",
    "    \n",
    "    nodes_idx = set()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Россия & США & Китай & !(Индия | Япония)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 result(s).\n",
      "http://lenta.ru/articles/2015/02/14/liberman/\n",
      "http://lenta.ru/articles/2015/12/16/rulers/\n",
      "http://lenta.ru/news/2005/07/15/china1/\n",
      "http://lenta.ru/articles/2015/08/20/ustrussia/\n",
      "http://lenta.ru/articles/2015/01/27/solar/\n",
      "http://lenta.ru/articles/2015/04/03/viet/\n",
      "http://lenta.ru/news/2008/02/12/lavrov/\n",
      "http://lenta.ru/articles/2010/03/30/review/\n",
      "http://lenta.ru/columns/2015/03/09/strategy/\n",
      "http://lenta.ru/sport/2003/07/18/soccer/\n",
      "http://lenta.ru/articles/2006/05/04/resolution/\n",
      "http://lenta.ru/articles/2002/08/08/weapon/\n",
      "http://lenta.ru/articles/2013/03/20/sipri/\n",
      "CPU times: user 2.78 ms, sys: 3.98 ms, total: 6.76 ms\n",
      "Wall time: 6.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result = search(query, id_to_url)\n",
    "\n",
    "print('Found', len(result), 'result(s).')\n",
    "print(*result, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сайты из выдачи поискового алгоритма проверил вручную, все они подходят под булев запрос."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
